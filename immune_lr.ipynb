{"cells":[{"cell_type":"code","source":["#import modules\nfrom pyspark import SparkConf, SparkContext\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import StringType, IntegerType, StructType, StructField\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql import functions as sqlFunc\n\n#set schema\ndf_schema = StructType([StructField(\"age\", IntegerType(), True), StructField(\"sex\", StringType(), True), \\\n                     StructField(\"lang\", StringType(), True), StructField(\"ethnicity\", StringType(), True), \\\n                     StructField(\"diabetes\", StringType(), True), StructField(\"alcoholism\", StringType(), True), \\\n                     StructField(\"hf\", StringType(),True), StructField(\"liver\", StringType(), True), \\\n                     StructField(\"lung\", StringType(), True), StructField(\"smoking\", StringType(), True), \\\n                     StructField(\"prior_pneumo\", StringType(), True), StructField(\"prior_tdap\", StringType(), True), \\\n                     StructField(\"post_pneumo\", StringType(), True), StructField(\"post_tdap\", StringType(), True)])\n\n#load data\ndirectory = 's3://applifier-mapreduce/elia/vaccines/vaccinations.csv'\ndf = spark.read.csv(path = directory, header = True, schema = df_schema)\ndf.persist()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":["##Clean Data"],"metadata":{}},{"cell_type":"code","source":["#clean non ordinal columns: sex, lang, ethnicity\ndf = df.withColumn(\"sex\", sqlFunc.trim(col(\"sex\")))\ndf = df.withColumn(\"sex\", sqlFunc.lower(col(\"sex\")))"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["df.select('sex').distinct().show()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["df = df.withColumn(\"lang\", sqlFunc.trim(col(\"lang\")))\ndf = df.withColumn(\"lang\", sqlFunc.lower(col(\"lang\")))\ndf = df.withColumn(\"lang\", sqlFunc.when(sqlFunc.trim(col('lang')) == 'unreported', 'unknown').otherwise(col('lang')))\ndf = df.withColumn(\"lang\", sqlFunc.when(col('lang') == 'haitian creole', 'haitian').otherwise(col('lang')))\ndf = df.withColumn(\"lang\", sqlFunc.when(col('lang') == 'unknown', 'other').otherwise(col('lang')))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["df.select('lang').distinct().show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["df = df.withColumn(\"ethnicity\", sqlFunc.trim(col(\"ethnicity\")))\ndf = df.withColumn(\"ethnicity\", sqlFunc.lower(col(\"ethnicity\")))\ndf = df.withColumn(\"ethnicity\", sqlFunc.when((col('ethnicity') == 'hisp')|(col('ethnicity') == 'hispanic or latino'), 'hispanic').otherwise(col('ethnicity')))\ndf = df.withColumn(\"ethnicity\", sqlFunc.when((col('ethnicity') == 'not hispanic or latino(black)')|(col('ethnicity') == 'not hispanic (black)')|(col('ethnicity') == 'not hispanic or latino (black)'), 'black/african american').otherwise(col('ethnicity')))\ndf = df.withColumn(\"ethnicity\", sqlFunc.when((col('ethnicity') == 'not hispanic (white)')|(col('ethnicity') == 'not hispanic or latino (white)'), 'white').otherwise(col('ethnicity')))\ndf = df.withColumn(\"ethnicity\", sqlFunc.when((col('ethnicity') == 'not hispanic or latino (asian)')|(col('ethnicity') == 'not hispanic (asian)'), 'asian').otherwise(col('ethnicity')))      \ndf = df.withColumn(\"ethnicity\", sqlFunc.when((col('ethnicity') == 'not hispanic or latino'), 'not hispanic').otherwise(col('ethnicity')))      \ndf = df.withColumn(\"ethnicity\", sqlFunc.when((col('ethnicity') == 'not hispanic (other)')|(col('ethnicity') == 'unknown'), 'other').otherwise(col('ethnicity')))\ndf = df.withColumn(\"ethnicity\", sqlFunc.when(col('ethnicity') == 'unreported', 'other').otherwise(col('ethnicity')))\ndf = df.withColumn(\"ethnicity\", sqlFunc.when(col('ethnicity') == 'not hispanic (native american)', 'native american').otherwise(col('ethnicity')))\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["df.select('ethnicity').distinct().show(n=15, truncate = False)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#impute missing categorical values\ndef convert_space_nulls(c):\n    '''\n    Convert categoricals that are null to NA\n    \n    '''\n    return (sqlFunc.when(sqlFunc.trim(col(c)) == '', \"NA\").when(col(c).isNull(), \"NA\").otherwise(col(c))).alias(c)\n\nexprs = [convert_space_nulls(c[0]) if c[1] == 'string' else c[0] for c in df.dtypes ]\n\ndf = df.select(*exprs)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#bucketize age for every 10 years starting at min\ndef age_bucket(x): \n    \n    if x == 0 or x < 0 or x == None: \n        return 'bin1'\n    if 18 <= x < 28:\n        return 'bin2'\n    if 28 <= x <38:\n        return 'bin3'\n    if 38<= x < 48:\n        return 'bin4'\n    if 48<= x < 58: \n        return 'bin5'\n    if 58 <= x < 68:\n        return 'bin6'\n    if 68 <= x < 78:\n        return 'bin7'\n    if 78 <= x < 88:\n        return 'bin8'\n    else:\n        return 'bin9'\n\nudf_age = udf(age_bucket, StringType())\ndf = df.withColumn(\"age_bucket\", udf_age(df.age))"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["##Preprocess and set up pipeline"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\nfrom pyspark.ml import Pipeline\n\n# create pipeline for model using post_pnuemo as target\nstages = [] \ncolumns = ['age_bucket', 'sex', 'lang', 'ethnicity', 'diabetes', 'alcoholism', 'hf', 'liver', 'lung', 'smoking', 'prior_pneumo', 'prior_tdap']\n\n# step 1: convert our target into a label using stringindexer\nlabel_indexer = StringIndexer(inputCol = 'post_pneumo', outputCol = 'label')\n\n# add these things to stages for ml pipeline\nstages += [label_indexer]\n\n# step 3: now we do some categorical indexing and encoding using string indexer and onehot\nfor column in columns: \n\n    # add hierarchal ordering to categories\n    stringIndexer = StringIndexer(inputCol = column, outputCol = column+'Index')\n\n    # now we need to encode this string into a binary vector\n    encoder = OneHotEncoder(inputCol = column+'Index', outputCol = column+'Vect')\n\n    stages += [stringIndexer, encoder]\n\nassemblerInput = [column+'Vect' for column in columns]\n\nassemble_feat = VectorAssembler(inputCols=assemblerInput, outputCol = 'features')\n\nstages += [assemble_feat]\n\n# build pipeline for model \npipeline = Pipeline(stages = stages)\n\n#run data through pipeline\npipeline_model = pipeline.fit(df)\ndataset = pipeline_model.transform(df)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["df.unpersist()\ndataset.persist()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["dataset.take(1)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["##Set up Logistic Regression (Binary)\n- This is predicting the probability of having a pnuemo vaccine given all other information about that individual excluding whether they had a tdap at that time. However, prior tdap and prior pnemo vaccine info is included"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n\n#split data\ntrain_fraction = 0.7\n(trainingData, testData) = dataset.randomSplit([train_fraction, 1-train_fraction], seed = 100)\n\n#train model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\nlr_model = lr.fit(trainingData)\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["trainingData.count()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["testData.count()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\nfrom pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n\n#test model with test data\ntest_predictions = lr_model.transform(testData)\npredictionAndLabels = test_predictions.select(\"prediction\", \"label\").rdd\nmetrics = MulticlassMetrics(predictionAndLabels)\nauc_metric = BinaryClassificationMetrics(predictionAndLabels).areaUnderROC\ncm = metrics.confusionMatrix().toArray()\naccuracy = (cm[0][0]+ cm[1][1])/(cm[0][1] + cm[1][0]+cm[0][0]+ cm[1][1])\nprecision = cm[0][0]/ (cm[0][0]+ cm[1][0])\nrecall = cm[0][0]/ (cm[0][0]+ cm[0][1])\n\nprint(\"****Summary Stats****\")\nprint (\"Confusion Matrix: \")\nprint cm\n\nprint(\"Area under ROC = %s\" % auc_metric)\nprint(\"Precision = %s\" % precision)\nprint(\"Recall = %s\" % recall)\nprint(\"Accuracy = %s\" % accuracy)\n"],"metadata":{},"outputs":[],"execution_count":19}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.12","nbconvert_exporter":"python","file_extension":".py"},"name":"vaccines","notebookId":8831},"nbformat":4,"nbformat_minor":0}
